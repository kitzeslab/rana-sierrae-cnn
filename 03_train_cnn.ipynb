{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ae7ceca-77b3-462a-accc-24f1e5190978",
   "metadata": {},
   "source": [
    "## Train CNN to detect Rana sierrae in audio recordings\n",
    "\n",
    "This script uses the training and validation data generated in 02_prep_training_data.ipynb to train\n",
    "a CNN using OpenSoundscape. \n",
    "\n",
    "Note that training is a stochastic process and will result in slightly different results each time\n",
    "the script is run. The original model object trained and used in the manuscript is included in \n",
    "the subfolder `./resources/rana_seirrae_cnn.model`. \n",
    "\n",
    "### This takes a long time\n",
    "Training a CNN deep learning model is computationaly expensive and slow. It is much faster when a GPU is available (OpenSoundscape will automatically use a GPU if it is available) but even so will take about an hour to run (estimated 20 hours for CPU only machine). \n",
    "\n",
    "You can proceed through the rest of the notebooks without re-training the model, instead using the original model object trained and used in the manuscript, which is included in \n",
    "the subfolder `./resources/rana_seirrae_cnn.model`. \n",
    "\n",
    "\n",
    "This notebook is part of a series of notebooks and scripts in the [repository](https://github.com/kitzeslab/rana-sierrae-cnn):\n",
    "\n",
    "- `01_explore_annotated_data.ipynb` Explore annotated dataset of Rana sierrae call types\n",
    "\n",
    "- `02_prep_training_data.ipynb` Prepare annotated files for training a CNN machine learning model\n",
    "\n",
    "- `03_train_cnn.ipynb` Train a CNN to recognize Rana sierrae vocaliztaions\n",
    "\n",
    "- `04_cnn_prediction.ipynb` Use the cnn to detect Rana sierrae in audio recordings\n",
    "\n",
    "- `05_cnn_validation.ipynb` Analyze the accuracy and performance of the CNN\n",
    "\n",
    "- `06_aggregate_scores.py` Aggregate scores from CNN prediction across dates and times of day\n",
    "\n",
    "- `07_explore_results.ipynb` Analyze temporal patterns of vocal activity using the CNN detections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1f6afb-a1dc-4926-92a3-72fff90075bd",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b459153-0424-4fc5-a4f2-6c2ba94e36e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from opensoundscape.torch.models.cnn import CNN\n",
    "from opensoundscape.data_selection import resample\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189df9c3-2522-47bc-9013-a5ee48299212",
   "metadata": {},
   "source": [
    "Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eda590a-90f3-41ee-84d9-903a67dc90e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and validation datasets prepared in the notebook 02_prep_training_data.ipynb\n",
    "train_df = pd.read_csv('./resources/training_set.csv').set_index(['file','start_time','end_time'])\n",
    "train_df['negative']=1-train_df['rana_sierrae']\n",
    "val_df = pd.read_csv('./resources/validation_set.csv').set_index(['file','start_time','end_time'])\n",
    "val_df['negative']=1-val_df['rana_sierrae']\n",
    "\n",
    "# upsample to match the class with the most samples (reuse samples from other classes)\n",
    "train_df = resample(train_df,upsample=True,n_samples_per_class=train_df.sum().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53c36f6-7ee2-4f7c-a279-39cfa06a953c",
   "metadata": {},
   "source": [
    "initialize wandb session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac4afac-79a4-4de9-9cc0-f816d601c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Weights and Biases logging session for tracking model training progress\n",
    "# requires log in to wandb the first time\n",
    "# can skip this non-critical step by passing wandb_session=None to train() and commenting\n",
    "# out these lines\n",
    "wandb_session = wandb.init(\n",
    "    entity='kitzeslab', #replace this with your WandB \"entity\" ie group name\n",
    "    project=\"rana_sierrae_notebooks\",\n",
    "    config=dict(\n",
    "        comment=\"Description: training resnet18 on A & E classes and excluding unknown class X\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ff7744-0b6f-4536-8ecd-c865fb53e977",
   "metadata": {},
   "source": [
    "create CNN with OpenSoundscape and customize preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53165f3e-57b4-4793-b270-448674e2f9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create opensoundscape.CNN object to train a CNN on audio\n",
    "model = CNN(architecture='resnet18',classes=train_df.columns,sample_duration=2.0,single_target=True)\n",
    "\n",
    "#modify preprocessing of the CNN:\n",
    "#bandpass spectrograms to 300-2000 Hz\n",
    "model.preprocessor.pipeline.bandpass.set(min_f=300,max_f=2000)\n",
    "#modify augmentation routine parameters\n",
    "model.preprocessor.pipeline.frequency_mask.set(max_masks=5,max_width=0.1)\n",
    "model.preprocessor.pipeline.time_mask.set(max_masks=5,max_width=0.1)\n",
    "model.preprocessor.pipeline.add_noise.set(std=0.01)\n",
    "\n",
    "# decrease the learning rate from the default value\n",
    "model.optimizer_params['lr']=0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d16428-6c38-469d-998b-fe82435cfe08",
   "metadata": {},
   "source": [
    "Train cnn for 20 epochs on Training set, evaluating on Validation set\n",
    "\n",
    "Trained models are saved to ./resources during the cell above, once every 5 epochs. The model performing best on the validation set is saved as `best.model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abe34c7-937b-41b7-9139-420b609dd711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train CNN for 20 epochs with batch size 128\n",
    "model.train(\n",
    "    train_df,\n",
    "    val_df,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    num_workers=12,\n",
    "    save_path=f'./resources/',\n",
    "    save_interval=5,\n",
    "    log_interval=10,\n",
    "    validation_interval=1,\n",
    "    wandb_session=wandb_session\n",
    ")\n",
    "\n",
    "#let wandb know this run finished successfully\n",
    "wandb_session.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opso080",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
